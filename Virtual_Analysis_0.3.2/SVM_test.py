# coding=UTF-8
import sklearn
import pickle
import numpy
import pandas
import Pcap_class
from sklearn.model_selection import train_test_split
import tensorflow as tf

PREPARE = 2


def distribution_collect(packet):
    meta_data = []
    length = packet.get_packet_head().get_real_len()
    src_p = packet.get_transport_head().get_ports()[0]
    dst_p = packet.get_transport_head().get_ports()[1]
    app_raw = packet.get_application_raw()
    meta_data.append(length)
    meta_data.append(src_p)
    meta_data.append(dst_p)
    for i in range(11):
        if app_raw != None:
            while len(app_raw) < 11:
                  app_raw.append(0)
            meta_data.append(app_raw[i])
        else:
            meta_data.append(0)
    return meta_data


def data_save(data, distribution_dict, packet_No):
    pd_data = pandas.DataFrame(data, columns=['length', 'Src_port', 'Dst_port', 'data_01', 'data_02', 'data_03'
                                              , 'data_04', 'data_05', 'data_06', 'data_07', 'data_08', 'data_09'
                                              , 'data_10', 'data_11'])
    distribution_dict[packet_No] = pd_data.dropna()


def data_process(x,y):
    X=pandas.DataFrame()
    Y=pandas.DataFrame()
    for i in x:
        X=X.append(i)
    for i in y:
        Y=Y.append(i)
    X,Y=sklearn.utils.shuffle(X,Y)
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)
    return X_train, X_test, y_train, y_test


def fileread(filename,label):
    f = open(filename + '.txt', 'rb')
    X = pickle.load(f)
    Y = pandas.DataFrame([label for i in range(X.shape[0])])
    return X, Y


if __name__ == '__main__':

    '''
    filename = "QQ"
    if PREPARE == 1:
        my_pcap_file = Pcap_class.build_pcap(filename + ".pcap", 1500)
        packets = my_pcap_file.get_packets()
        packet_list = []
        packet_num = 0
        for packet in packets:
            data = distribution_collect(packet)
            packet_list.append(data)
            packet_num += 1
            if packet_num > 40:
                break
        pd_data = pandas.DataFrame(packet_list, columns=['length', 'Src_port', 'Dst_port', 'data_01', 'data_02', 'data_03',
                                                  'data_04', 'data_05', 'data_06', 'data_07', 'data_08', 'data_09',
                                                  'data_10', 'data_11'])
        f = open(filename + '.txt', 'wb')
        pickle.dump(pd_data, f)
        f.close()
    elif PREPARE == 0:
        x_r,y_r = fileread("QQ",1)
        x_w,y_w = fileread("test1",0)
        scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(0, 1))
        X_train, X_test, y_train, y_test = data_process([x_r, x_w], [y_r, y_w])
        X_train = scaler.fit_transform(X_train)
        X_test = scaler.fit_transform(X_test)
        X_train = X_train.reshape((X_train.shape[0], 1, 14))
        X_test = X_test.reshape((X_test.shape[0], 1, 14))
        model = tf.keras.models.Sequential()
        model.add(tf.keras.layers.LSTM(32, input_shape=(1, 14)))
        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))
        model.compile(loss='binary_crossentropy',
                      optimizer='rmsprop',
                      metrics=['accuracy'])
        model.fit(X_train, y_train, batch_size=16, epochs=50)
        score, acc = model.evaluate(X_test, y_test, batch_size=32)
        print(score)
        print(acc)
        model.save("test.model")
    elif PREPARE == 2:
        filename = "QQ2"
        my_pcap_file = Pcap_class.build_pcap(filename + ".pcap", 30)
        packets = my_pcap_file.get_packets()
        packet_list = []
        packet_num = 0
        for packet in packets:
            data = distribution_collect(packet)
            packet_list.append(data)
            packet_num += 1
            if packet_num > 40:
                break
        model = tf.keras.models.load_model('test.model')
        test_data = pandas.DataFrame(packet_list, columns=['length', 'Src_port', 'Dst_port', 'data_01', 'data_02', 'data_03'
            , 'data_04', 'data_05', 'data_06', 'data_07', 'data_08', 'data_09'
            , 'data_10', 'data_11'])
        test_data = test_data.values
        test_data = test_data.reshape((test_data.shape[0], 1, 14))
        prediction = model.predict(test_data)
        #prediction = model.predict(test_data)
        print(prediction)
'''
'''
if __name__ == '__main__':
    aa = {}
    for a in range(10):
        aa[a] = [a + 10, "line"]
    aa[10] = [30,"point"]
    f = open('svm_test.txt', 'wb')
    pickle.dump(aa, f, 0)
    f.close()
    f = open('svm_test.txt', 'rb')
    bb = pickle.load(f)
    print(bb)
    f.close()
    for i in bb:
        print(bb[i])

    cc = [1,2,3]
    dd = []
    dd.append(cc)
    print(dd)
    pd_data = pandas.DataFrame(dd, columns=['length', 'delta', 'direction'])
    ee = {}
    ee[1] = pd_data.dropna()
    ee[2] = pd_data.dropna()
    print(ee)
    Y = pandas.DataFrame([2 for i in range(10)])
    print(Y)
'''
